{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests import get \n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialized constant to crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = ['Son%20La%20Viet%20Nam','Lang%20Son',\n",
    "            'Hanoi', 'Nghe%20An', 'Da%20Nang', 'Lam%20Dong',\n",
    "            ]\n",
    "location_name = ['SonLa', 'LangSon']\n",
    "\n",
    "base_api = 'https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/{location}/{date1}/{date2}?key={api_key}'\n",
    "parameter = { \n",
    "    'include' : 'days',\n",
    "    'unitGroup': 'metric'\n",
    "}\n",
    "\n",
    "years = [2019, 2021, 2023]\n",
    "day_base = ['-01-01','-12-31'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CallAPI() function \n",
    "- Parameters:\n",
    "    - timesIndex: used to count the times to crawl per day \n",
    "        - Because using free API key constraint this code to crawl 1000 indexes perday\n",
    "    - location_str: Location string using in API parameters\n",
    "    - location_name: Location name to store backup datas to files in case there's error in runtime\n",
    "- Idea: \n",
    "    - Call the API using the structure defined in the documents\n",
    "    - Get the data in the binary form\n",
    "    - Decode binary data to utf-8\n",
    "    - Parse data using json module\n",
    "    - Return the parsed json data\n",
    "- Warnings:  \n",
    "    - API key must be stored in 'key.txt' file in the same directory as this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callAPI(timesIndex: int, location_str: str, location_name: str) -> list: \n",
    "    # Get api key from file \n",
    "    key_file = open('key.txt','r')\n",
    "    key_content = key_file.read()\n",
    "    key_file.close()\n",
    "    \n",
    "    # construct api link\n",
    "    day1 = str(years[timesIndex]) + day_base[0]\n",
    "\n",
    "    # Third time just call 1 year \n",
    "    if timesIndex == 2: \n",
    "        day2 = str(years[timesIndex] + 1) + day_base[0]\n",
    "    else:\n",
    "        day2 = str(years[timesIndex] + 1) + day_base[1]\n",
    "\n",
    "    run_api = base_api.format(location=location_str, \n",
    "                              date1=day1,\n",
    "                              date2=day2,\n",
    "                              api_key=key_content)\n",
    "\n",
    "    # Call the api \n",
    "    try: \n",
    "        request_content = get(run_api, params= parameter)\n",
    "        if request_content.status_code != 200:\n",
    "            raise 'Get() method failed'\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "    # Decode binary data to text\n",
    "    json_content = request_content.content\n",
    "    json_content = json_content.decode('utf-8')\n",
    "\n",
    "    # Create backups\n",
    "    jsonFile = open('jsonData'+str(timesIndex)+ location_name +  '.txt','+a')\n",
    "    jsonFile.write(json_content)\n",
    "    jsonFile.close()\n",
    "\n",
    "    # Parse json \n",
    "    json_values = json.loads(json_content)\n",
    "    return json_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert_data_frame() function\n",
    "- Parameters\n",
    "    - json_values: parsed json datas from the callAPI() function\n",
    "    - location_name: location's name to store to file \n",
    "    - times: used to name files \n",
    "- Idea: \n",
    "    - Get every single day data as object \n",
    "    - Append all values to a 2D array \n",
    "    - Get all columns's name \n",
    "    - Pass through pd.DataFrame function to convert python map to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_frame(json_values, location_name, times) -> pd.DataFrame: \n",
    "    # Get attributes length\n",
    "    datas = json_values['days']\n",
    "    day_temp = datas[0]\n",
    "    feature_count = len(day_temp)\n",
    "\n",
    "\n",
    "    feature_name = []\n",
    "    # Get attributes's name\n",
    "    for attri in day_temp: \n",
    "        feature_name.append(attri)\n",
    "\n",
    "    values = [[] for x in range(feature_count + 1)]\n",
    "    print(values)\n",
    "\n",
    "    # Get attributes values\n",
    "    for day in datas:\n",
    "        i = 0\n",
    "        for attribute in day: \n",
    "            print(i)\n",
    "            values[i].append(day[attribute])\n",
    "            \n",
    "            i = i + 1\n",
    "\n",
    "    # Construct dataframe\n",
    "    df_map = {}\n",
    "    for i in range(feature_count):\n",
    "        df_map.update({feature_name[i] : values[i]})\n",
    "    raw_df = pd.DataFrame(df_map)\n",
    "    raw_df.to_csv(location_name +str(times) + '.csv',sep=',')\n",
    "    return raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CrawlData() function \n",
    "- call 2 functions above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawlData(location_link: str, location_alias: str, day: int = 0): \n",
    "    json_data = callAPI(timesIndex=day, location_str=location_link,location_name=location_alias)\n",
    "    raw_df = convert_data_frame(json_values=json_data,location_name=location_alias, times=day)\n",
    "    print(raw_df.head())\n",
    "    # use for debugging\n",
    "    return json_data, raw_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawl data for every single day  \n",
    "- Notes: both location day 2 can be crawled at the same day because there's just 1 year each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_deb, df_deb = crawlData(location[0],location_name[0],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_deb, df_deb = crawlData(location[0],location_name[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_deb, df_deb = crawlData(location[0],location_name[0],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_deb, df_deb = crawlData(location[1],location_name[1],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_deb, df_deb = crawlData(location[1],location_name[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_deb, df_deb = crawlData(location[1],location_name[1],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge all discrete csv files to a single location csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_list = ['LangSon', 'SonLa']\n",
    "\n",
    "for location in local_list: \n",
    "    df_list = []\n",
    "    for i in range(3): \n",
    "        df_list.append(pd.read_csv(location + str(i) + '.csv'))\n",
    "    full_df = pd.concat(df_list)\n",
    "    full_df.to_csv(location + '.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
